from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Создаем сессию Spark
spark = SparkSession.builder.appName("ProductCategory").getOrCreate()

# Создаем датафреймы с продуктами и категориями
products = spark.read.csv("products.csv", header=True)
categories = spark.read.csv("categories.csv", header=True)

# Соединяем датафреймы по ключу (Id продукта)
joined_df = products.join(categories, products["ProductId"] == categories["ProductId"], "left_outer")

# Фильтруем записи, где нет категорий
products_without_categories = joined_df.filter(col("CategoryId").isNull())

# Выбираем только нужные столбцы и печатаем результат
result_df = joined_df.select("ProductName", "CategoryName")
products_without_categories.show()
